{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05.Karas_김우섭.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Woosub-Kim/test_git/blob/master/05_Karas_%EA%B9%80%EC%9A%B0%EC%84%AD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcUYe822YxGp",
        "colab_type": "text"
      },
      "source": [
        "## load MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNdAlRXi2ky2",
        "colab_type": "code",
        "outputId": "faca6cec-fd48-4646-ab68-5dfde15c1770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w24J5wa53dJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop, Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rpef0RND37pQ",
        "colab_type": "code",
        "outputId": "06c88202-c335-4b93-ab2c-65a9254cf369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f72ff1cf208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSRB2IAnCDiTx/65XcTNOWsh5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lfwQbFoM0lU",
        "colab_type": "text"
      },
      "source": [
        "## 원래 x_train데이터는 0~255까지의 색 코드를 담고있는 \n",
        "## 28 x 28 행렬 60000개를 담고있는 \n",
        "## np.array이다(60000x28x28)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3tXk7Bm4RZb",
        "colab_type": "code",
        "outputId": "c8c44001-329d-4e9e-f0f1-bd6715c36578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnVMfrvmGt-g",
        "colab_type": "code",
        "outputId": "55bbf82f-31a1-4c60-b2d2-07e4963f1b2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(3):\n",
        "  print(x_train[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  51 159 253\n",
            "  159  50   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  48 238 252 252\n",
            "  252 237   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  54 227 253 252 239\n",
            "  233 252  57   6   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202\n",
            "   84 252 253 122   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 163 252 252 252 253 252 252\n",
            "   96 189 253 167   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253 228\n",
            "   47  79 255 168   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  48 238 252 252 179  12  75 121  21\n",
            "    0   0 253 243  50   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  38 165 253 233 208  84   0   0   0   0\n",
            "    0   0 253 252 165   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   7 178 252 240  71  19  28   0   0   0   0\n",
            "    0   0 253 252 195   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  57 252 252  63   0   0   0   0   0   0   0\n",
            "    0   0 253 252 195   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 198 253 190   0   0   0   0   0   0   0   0\n",
            "    0   0 255 253 196   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  76 246 252 112   0   0   0   0   0   0   0   0\n",
            "    0   0 253 252 148   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0\n",
            "    7 135 253 186  12   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 223   0   0   0   0   0   0   0   0   7\n",
            "  131 252 225  71   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48 165\n",
            "  252 173   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  86 253 225   0   0   0   0   0   0 114 238 253\n",
            "  162   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 249 146  48  29  85 178 225 253 223 167\n",
            "   56   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 252 252 229 215 252 252 252 196 130   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  28 199 252 252 253 252 252 233 145   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  25 128 252 253 252 141  37   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0  67 232  39   0   0   0   0   0]\n",
            " [  0   0   0   0  62  81   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0 120 180  39   0   0   0   0   0]\n",
            " [  0   0   0   0 126 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   2 153 210  40   0   0   0   0   0]\n",
            " [  0   0   0   0 220 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0  27 254 162   0   0   0   0   0   0]\n",
            " [  0   0   0   0 222 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0 183 254 125   0   0   0   0   0   0]\n",
            " [  0   0   0  46 245 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0 198 254  56   0   0   0   0   0   0]\n",
            " [  0   0   0 120 254 163   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   23 231 254  29   0   0   0   0   0   0]\n",
            " [  0   0   0 159 254 120   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  163 254 216  16   0   0   0   0   0   0]\n",
            " [  0   0   0 159 254  67   0   0   0   0   0   0   0   0   0  14  86 178\n",
            "  248 254  91   0   0   0   0   0   0   0]\n",
            " [  0   0   0 159 254  85   0   0   0  47  49 116 144 150 241 243 234 179\n",
            "  241 252  40   0   0   0   0   0   0   0]\n",
            " [  0   0   0 150 253 237 207 207 207 253 254 250 240 198 143  91  28   5\n",
            "  233 250   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 119 177 177 177 177 177  98  56   0   0   0   0   0 102\n",
            "  254 220   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
            "  254 137   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
            "  254  57   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
            "  254  57   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
            "  255  94   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
            "  254  96   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
            "  254 153   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
            "  255 153   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  96\n",
            "  254 153   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3IO6t_VNLoe",
        "colab_type": "text"
      },
      "source": [
        "## 0~255까지 색깔보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5Szjpm8HZhw",
        "colab_type": "code",
        "outputId": "aba3359d-d187-4bd1-fbd2-b2de1543d2ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import numpy as np\n",
        "image = np.array(list(x for x in range(256))).reshape(16,16)\n",
        "plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f72815a6cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD4CAYAAAAjDTByAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAPlElEQVR4nO3dfYxc1X3G8e+zs37BxvFLXQjBVg0p\nQnLTFyyLkjSiUd1S4yKcSvnDqGlNiBRFLS1UqZBTpCbqX0nTpq9RIhdoaWtBVAKNFUGDS4iiSsEN\nuDbYmMSGErBrMK1bGwLENvvrH3OXjtc73plz7z3e9Xk+0mpnZ+7Z89sz88y9c3fOHEUEZlaekbNd\ngJmdHQ6/WaEcfrNCOfxmhXL4zQo1mrOz2ZoTc5mfs8vhKVujZGkl5q0xSXKJGf+2rMM4fGdvvPUq\nx8feGKhh1vDPZT4/qzXDN0x54CrtoEYj+foipS9AKeMxklhj6pNGQn9JfxekjWPm+yzXY/jbR+4b\neFsf9psVyuE3K1St8EtaK+m7kvZL2tRUUWbWvuTwS+oAXwCuBVYCN0ha2VRhZtauOnv+K4H9EfFc\nRBwH7gXWN1OWmbWtTvgvBl7s+flAdd0pJH1M0uOSHj/BD2t0Z2ZNav2EX0RsjojVEbF6FnPa7s7M\nBlQn/AeB5T0/L6uuM7MZoE74vwNcJukSSbOBDcDWZsoys7Ylv8MvIk5Kuhn4OtAB7oqIPY1VZmat\nqvX23oh4EHiwoVrMLCO/w8+sUFkn9mh0lM7SC4ZvlzQpIt+ElOS+sk5kyVxjQrvIOmnmHL3PjnUG\n3tR7frNCOfxmhXL4zQrl8JsVyuE3K5TDb1Yoh9+sUA6/WaEcfrNCOfxmhXL4zQrl8JsVKuvEHkY7\nsHTx0M3GklaoGb4JkHWSSCRPEklok3kiS6Q0S5zYkzSOqctu5RyPlMlR3x/8weE9v1mhHH6zQjn8\nZoWqs2LPckmPSnpa0h5JtzRZmJm1q84Jv5PAJyJih6QFwBOStkXE0w3VZmYtSt7zR8ShiNhRXX4V\n2MskK/aY2fTUyGt+SSuAK4Dtk9z29nJdx996vYnuzKwBtcMv6XzgK8CtEXFs4u29y3XN7syr252Z\nNaRW+CXNohv8LRFxfzMlmVkOdc72C7gT2BsRn2+uJDPLoc6e/+eAXwd+QdLO6mtdQ3WZWcvqrNX3\nr6S/Q9rMzjK/w8+sUFln9cXoCCeWDn/GP+esrbx9pbVLmf2W3FfWWWxJXSW1S55RmXpfJ83EHL7J\n2OjgjbznNyuUw29WKIffrFAOv1mhHH6zQjn8ZoVy+M0K5fCbFcrhNyuUw29WKIffrFAOv1mhsk7s\nGRsd4c0ls4dvmDRxY/g2+fua/pNmZsY4pvSVeWJPpvssOp7YY2ZTcPjNCuXwmxWqiY/u7kj6d0lf\na6IgM8ujiT3/LXRX6zGzGaTu5/YvA34FuKOZcswsl7p7/j8DbgPGGqjFzDKqs2jHdcDhiHhiiu3e\nXqvvxA9fS+3OzBpWd9GO6yU9D9xLd/GOf5i4Ue9afbPmnF+jOzNrUp0luj8ZEcsiYgWwAfhGRHy4\nscrMrFX+P79ZoRp5b39EfBP4ZhO/y8zy8J7frFB5l+vqwJuLEp5vpvkMMc+Ym6y/fMuezYzxyNPX\nWGfwbb3nNyuUw29WKIffrFAOv1mhHH6zQjn8ZoVy+M0K5fCbFcrhNyuUw29WKIffrFAOv1mhHH6z\nQmVeqw+OLxp+qtK0X5vuHJ0hltxXqhkwHtO9xvCsPjObisNvViiH36xQdVfsWSTpPknPSNor6b1N\nFWZm7ap7wu/PgX+OiA9Jmg3Ma6AmM8sgOfySFgJXAzcCRMRx4HgzZZlZ2+oc9l8CvAL8TbVE9x2S\n5k/cqHe5rrde/0GN7sysSXXCPwqsAr4YEVcAPwA2Tdyod7muzrzTnhvM7CypE/4DwIGI2F79fB/d\nJwMzmwHqrNX3EvCipMurq9YATzdSlZm1ru7Z/t8GtlRn+p8DPlK/JDPLoVb4I2InsLqhWswso+zL\ndR1fmNAuaVJEJDTyJJGm2iWN/oxYrivtcZWrRk/sMbMpOfxmhXL4zQrl8JsVyuE3K5TDb1Yoh9+s\nUA6/WaEcfrNCOfxmhXL4zQrl8JsVyuE3K9RZmNU3NnzD6T5rK/OMubTxyDcbrVa7pL5mwn2WqcbO\n4P14z29WKIffrFAOv1mh6i7X9buS9kjaLekeSXObKszM2pUcfkkXA78DrI6I9wAdYENThZlZu+oe\n9o8C50kapbtO33/WL8nMcqjzuf0HgT8GXgAOAUcj4uGJ252yXNdrXq7LbLqoc9i/GFhPd82+dwHz\nJX144nanLNd1vpfrMpsu6hz2/yLwHxHxSkScAO4H3tdMWWbWtjrhfwG4StI8SaK7XNfeZsoys7bV\nec2/ne7inDuAp6rftbmhusysZXWX6/oU8KmGajGzjPwOP7NCZZ3VRycYW3hy+HYJM6I03WdfAco4\n024k89p0ScsJJo9HvsdHao0p/aX0pdHBZ816z29WKIffrFAOv1mhHH6zQjn8ZoVy+M0K5fCbFcrh\nNyuUw29WKIffrFAOv1mhHH6zQmWd2DPSGWPewjeGbpdrUkRqu9Q5MyM5a0zsK3VCUEp/Occjua+k\nVmn9pbQ5OOKJPWY2BYffrFAOv1mhpgy/pLskHZa0u+e6JZK2SdpXfV/cbplm1rRB9vx/C6ydcN0m\n4JGIuAx4pPrZzGaQKcMfEd8Cjky4ej1wd3X5buCDDddlZi1Lfc1/YUQcqi6/BFzYb8Pe5bpOHns9\nsTsza1rtE34REUDff0j2Ltc1+o55dbszs4akhv9lSRcBVN8PN1eSmeWQGv6twMbq8kbgq82UY2a5\nDPKvvnuAbwOXSzog6aPAZ4BfkrSP7oKdn2m3TDNr2pTv7Y+IG/rctKbhWswsI7/Dz6xQWWf1jXbG\nuOAdrw3dLteMKICR/v+46Ct9xly+djnHo9vf4LPL/r/NuTweKTUOP4Z7OoMvh+c9v1mhHH6zQjn8\nZoVy+M0K5fCbFcrhNyuUw29WKIffrFAOv1mhHH6zQjn8ZoVy+M0KlXViz5yRk6xYMPGzQKeWMpki\nfZLI8JMpOufwpJkOw/eV2l/OGpP7Shh7SLuvU/p6dMQTe8xsCg6/WaEcfrNCpS7X9TlJz0h6UtID\nkha1W6aZNS11ua5twHsi4qeA7wGfbLguM2tZ0nJdEfFwRIyfVnwMWNZCbWbWoiZe898EPNTvxt7l\nut783zcb6M7MmlAr/JJuB04CW/pt07tc19xFc+t0Z2YNSn6Tj6QbgeuANdV6fWY2gySFX9Ja4Dbg\n5yPCS++azUCpy3X9FbAA2CZpp6QvtVynmTUsdbmuO1uoxcwy8jv8zAqVfVbfZfMOD90uZXZTysw3\ngE7SDMJ8faX2l3N2Xmp/6TPm8s3ETB/HlPts+BrnjpwYeFvv+c0K5fCbFcrhNyuUw29WKIffrFAO\nv1mhHH6zQjn8ZoVy+M0K5fCbFcrhNyuUw29WKIffrFBZZ/WdN3KclecdHLpd2qytjLP6Emd6Za0x\nua+ZUGPCOnjJMypTZwOmPK4SZvXJs/rMbAoOv1mhkpbr6rntE5JC0tJ2yjOztqQu14Wk5cA1wAsN\n12RmGSQt11X5U7of3+3P7DebgZJe80taDxyMiF0DbPv2cl1Hj5ycanMzy2Tof/VJmgf8Pt1D/ilF\nxGZgM8CP/+Q8HyWYTRMpe/53A5cAuyQ9T3eF3h2S3tlkYWbWrqH3/BHxFHDB+M/VE8DqiPivBusy\ns5alLtdlZjNc6nJdvbevaKwaM8vG7/AzK1TWiT1zdZKVs18eul3apIg0HQ3fJrmv1HYavsj0GhMG\nBBhJqDG5r4S/rqO0EUnpq9suYTwSajxviDbe85sVyuE3K5TDb1Yoh9+sUA6/WaEcfrNCOfxmhXL4\nzQrl8JsVyuE3K5TDb1Yoh9+sUA6/WaEUke9j9SS9Any/z81LgenwaUCu41Su41TTvY4fi4gfHeQX\nZA3/mUh6PCJWuw7X4Try1OHDfrNCOfxmhZpO4d98tguouI5TuY5TnTN1TJvX/GaW13Ta85tZRg6/\nWaGyhl/SWknflbRf0qZJbp8j6cvV7dslrWihhuWSHpX0tKQ9km6ZZJsPSDoqaWf19QdN19HT1/OS\nnqr6eXyS2yXpL6oxeVLSqob7v7zn79wp6ZikWyds09p4SLpL0mFJu3uuWyJpm6R91ffFfdpurLbZ\nJ2ljC3V8TtIz1bg/IGlRn7ZnvA8bqOPTkg72jP+6Pm3PmK/TRESWL7qfVP0scCkwG9gFrJywzW8C\nX6oubwC+3EIdFwGrqssLgO9NUscHgK9lGpfngaVnuH0d8BAg4Cpge8v30Ut03yiSZTyAq4FVwO6e\n6/4I2FRd3gR8dpJ2S4Dnqu+Lq8uLG67jGmC0uvzZyeoY5D5soI5PA783wH13xnxN/Mq5578S2B8R\nz0XEceBeYP2EbdYDd1eX7wPWSAkfAH8GEXEoInZUl18F9gIXN9lHw9YDfxddjwGLJF3UUl9rgGcj\not+7MBsXEd8Cjky4uvdxcDfwwUma/jKwLSKORMT/ANuAtU3WEREPR8T4uvKP0V2UtlV9xmMQg+Tr\nFDnDfzHwYs/PBzg9dG9vUw36UeBH2iqoellxBbB9kpvfK2mXpIck/URbNQABPCzpCUkfm+T2Qcat\nKRuAe/rclms8AC6MiEPV5ZeACyfZJue4ANxE9whsMlPdh024uXr5cVefl0FDj0exJ/wknQ98Bbg1\nIo5NuHkH3UPfnwb+EvinFkt5f0SsAq4FfkvS1S321Zek2cD1wD9OcnPO8ThFdI9pz+r/oyXdDpwE\ntvTZpO378IvAu4GfAQ4Bf9LEL80Z/oPA8p6fl1XXTbqNpFFgIfDfTRciaRbd4G+JiPsn3h4RxyLi\nteryg8AsSUubrqP6/Qer74eBB+gevvUaZNyacC2wIyJOW08t53hUXh5/aVN9PzzJNlnGRdKNwHXA\nr1VPRKcZ4D6sJSJejoi3ImIM+Os+v3/o8cgZ/u8Al0m6pNrLbAC2TthmKzB+1vZDwDf6DXiq6hzC\nncDeiPh8n23eOX6uQdKVdMepjSeh+ZIWjF+me4Jp94TNtgK/UZ31vwo42nNI3KQb6HPIn2s8evQ+\nDjYCX51km68D10haXB0GX1Nd1xhJa4HbgOsj4vU+2wxyH9ato/ccz6/2+f2D5OtUTZyhHOJM5jq6\nZ9efBW6vrvtDuoMLMJfuYed+4N+AS1uo4f10DyOfBHZWX+uAjwMfr7a5GdhD94zpY8D7WhqPS6s+\ndlX9jY9Jby0CvlCN2VPA6hbqmE83zAt7rssyHnSfcA4BJ+i+Tv0o3fM8jwD7gH8BllTbrgbu6Gl7\nU/VY2Q98pIU69tN9HT3+OBn/T9S7gAfPdB82XMffV/f9k3QDfdHEOvrl60xffnuvWaGKPeFnVjqH\n36xQDr9ZoRx+s0I5/GaFcvjNCuXwmxXq/wDSMV6dE0BmmAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcI__fiwXQYu",
        "colab_type": "text"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp3M1Yhh5z2o",
        "colab_type": "code",
        "outputId": "5e3c0d1f-de53-47ee-db92-f57c05fc0afd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TkAhHhv6U4F",
        "colab_type": "code",
        "outputId": "3d4f59ca-8bd9-43f3-df83-004217c5dc84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "source": [
        "num_classes = 10\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,))) # input layer\n",
        "model.add(Dense(512, activation='relu')) # hidden layer1\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CKSUlF36Y8m",
        "colab_type": "code",
        "outputId": "40d31eb6-59c4-461b-90ae-2f18c4741fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "source": [
        "# model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.001), metrics=['accuracy'])\n",
        "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.00001), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQn4qKtSDUK1",
        "colab_type": "text"
      },
      "source": [
        "## Model fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfeLUR5L6_xV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD-9JSSMFViy",
        "colab_type": "code",
        "outputId": "f424dff6-7324-4e19-ba27-fbf7fe4a4dd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "x_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MV76sGjocvI",
        "colab_type": "code",
        "outputId": "e2923bfb-c135-4f7d-e221-e890df4b7d73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        }
      },
      "source": [
        "\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "# with tf.device('/device:GPU:0'):\n",
        "# history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test), callbacks=[tbCallBack])\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 1.7282 - acc: 0.6305 - val_loss: 1.1504 - val_acc: 0.8090\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.8197 - acc: 0.8405 - val_loss: 0.5669 - val_acc: 0.8712\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.4948 - acc: 0.8790 - val_loss: 0.4096 - val_acc: 0.8977\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.3900 - acc: 0.8972 - val_loss: 0.3456 - val_acc: 0.9080\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.3390 - acc: 0.9080 - val_loss: 0.3083 - val_acc: 0.9164\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.3072 - acc: 0.9156 - val_loss: 0.2844 - val_acc: 0.9222\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.2840 - acc: 0.9220 - val_loss: 0.2669 - val_acc: 0.9248\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.2661 - acc: 0.9260 - val_loss: 0.2513 - val_acc: 0.9282\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.2511 - acc: 0.9307 - val_loss: 0.2387 - val_acc: 0.9313\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.2384 - acc: 0.9342 - val_loss: 0.2286 - val_acc: 0.9339\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDA6u1yCLyjy",
        "colab_type": "code",
        "outputId": "2f769128-efe3-4c81-9bf4-6f8bc848f86f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "  score = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print(model.metrics_names)\n",
        "  print('test loss: ', score[0])\n",
        "  print('test acc: ', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'acc']\n",
            "test loss:  0.2286375914245844\n",
            "test acc:  0.9339\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQcLtDUApc5t",
        "colab_type": "code",
        "outputId": "331c6dc7-14f1-4610-8c7b-11d00cf6a990",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqOVKKS_B08-",
        "colab_type": "text"
      },
      "source": [
        "## left keras logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bn4nQhbnIQA",
        "colab_type": "code",
        "outputId": "c1d47837-4323-4719-d0be-db70a028657e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        }
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "LOG_DIR = 'drive/data/tb_logs'\n",
        "\t\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\t\n",
        "import os\n",
        "if not os.path.exists(LOG_DIR):\n",
        "  os.makedirs(LOG_DIR)\n",
        "\t\n",
        "get_ipython().system_raw('tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'.format(LOG_DIR))\n",
        "\t\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\t\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "\"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "\n",
        "tbCallBack = TensorBoard(\n",
        "    log_dir=LOG_DIR, histogram_freq=1,\n",
        "    write_graph=True,\n",
        "    write_grads=True,\n",
        "    batch_size=batch_size,\n",
        "    write_images=True\n",
        ")\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test), callbacks=[tbCallBack])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-04 05:54:19--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.227.168.133, 52.201.174.2, 50.17.165.171, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.227.168.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.3’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  14.0MB/s    in 0.9s    \n",
            "\n",
            "2020-03-04 05:54:20 (14.0 MB/s) - ‘ngrok-stable-linux-amd64.zip.3’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ngrok                   \n",
            "https://711a9db1.ngrok.io\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1068: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1112: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.2274 - acc: 0.9371 - val_loss: 0.2184 - val_acc: 0.9374\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1265: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.2174 - acc: 0.9396 - val_loss: 0.2098 - val_acc: 0.9397\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.2086 - acc: 0.9420 - val_loss: 0.2027 - val_acc: 0.9421\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.2006 - acc: 0.9441 - val_loss: 0.1958 - val_acc: 0.9430\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1931 - acc: 0.9463 - val_loss: 0.1896 - val_acc: 0.9448\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1864 - acc: 0.9476 - val_loss: 0.1835 - val_acc: 0.9465\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.1802 - acc: 0.9493 - val_loss: 0.1787 - val_acc: 0.9473\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.1743 - acc: 0.9513 - val_loss: 0.1738 - val_acc: 0.9487\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.1688 - acc: 0.9523 - val_loss: 0.1695 - val_acc: 0.9498\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.1636 - acc: 0.9542 - val_loss: 0.1647 - val_acc: 0.9505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXKUTOcQ8lo5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rFcvFPPD9oR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(history.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfQ5VuBb8qcN",
        "colab_type": "code",
        "outputId": "8dc094f0-b6a2-4e34-f7e6-6979fd715149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "df = pd.DataFrame(history.history)\n",
        "df.plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f72fe3b3c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhJBCncRkQj6/8e4uvQT9s41AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oux0YEnqpfm",
        "colab_type": "code",
        "outputId": "cf147e8b-54fe-4729-a336-53d02095d860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        }
      },
      "source": [
        "history.history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc': [0.9370999999682108,\n",
              "  0.9395500000317891,\n",
              "  0.9420333333015442,\n",
              "  0.9440833333651225,\n",
              "  0.9462833333651225,\n",
              "  0.94765,\n",
              "  0.9492500000317892,\n",
              "  0.9512666666348776,\n",
              "  0.9522833333651225,\n",
              "  0.9541666666666667],\n",
              " 'loss': [0.22737287734349568,\n",
              "  0.21742865818341572,\n",
              "  0.2085715906023979,\n",
              "  0.20059612621863684,\n",
              "  0.19310847152868907,\n",
              "  0.18638081984917323,\n",
              "  0.18018879838784535,\n",
              "  0.17427873318990073,\n",
              "  0.16878442698717117,\n",
              "  0.16364366029898325],\n",
              " 'val_acc': [0.9374,\n",
              "  0.9397,\n",
              "  0.9421,\n",
              "  0.943,\n",
              "  0.9448,\n",
              "  0.9465,\n",
              "  0.9473,\n",
              "  0.9487,\n",
              "  0.9498,\n",
              "  0.9505],\n",
              " 'val_loss': [0.2183712172985077,\n",
              "  0.20983006801605225,\n",
              "  0.20272022205591203,\n",
              "  0.1957892426133156,\n",
              "  0.18961155593395232,\n",
              "  0.1835458195269108,\n",
              "  0.17869619890451433,\n",
              "  0.17375004712343217,\n",
              "  0.16946835255622864,\n",
              "  0.16469463438987733]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SwWKgCoNfNQ",
        "colab_type": "text"
      },
      "source": [
        "## 파라미터 조절하기 \n",
        "#### compile의 lr값(학습률)\n",
        "#### activation의 학습방법\n",
        "#### compile의 loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3JWa7CvEIis",
        "colab_type": "code",
        "outputId": "97d3c440-fe4b-430a-b4e0-21515c29a1eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "# compile과정의 lr값을 조정 학습률\n",
        "model1 = Sequential()\n",
        "model1.add(Dense (512, activation='relu', input_shape=(784,))) # input layer\n",
        "model1.add(Dense(512, activation='relu')) # hidden layer1\n",
        "model1.add(Dense(num_classes, activation='softmax'))\n",
        "model1.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.001), metrics=['accuracy'])\n",
        "history1 = model1.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=(x_test, y_test))\n",
        "\n",
        "#add에서 activation을 모두 softmax \n",
        "model2 = Sequential()\n",
        "model2.add(Dense (512, activation='softmax', input_shape=(784,))) # input layer\n",
        "model2.add(Dense(512, activation='softmax')) # hidden layer1\n",
        "model2.add(Dense(num_classes, activation='softmax'))\n",
        "model2.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.00001), metrics=['accuracy'])\n",
        "history2 = model2.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=(x_test, y_test))\n",
        "\n",
        "#add에서 activation을 모두 relu\n",
        "model3 = Sequential()\n",
        "model3.add(Dense (512, activation='relu', input_shape=(784,))) # input layer\n",
        "model3.add(Dense(512, activation='relu')) # hidden layer1\n",
        "model3.add(Dense(num_classes, activation='relu'))\n",
        "model3.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.00001), metrics=['accuracy'])\n",
        "history3 = model3.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=(x_test, y_test))\n",
        "\n",
        "#compile과정에서 loss 를 mean_squared_error\n",
        "model4 = Sequential()\n",
        "model4.add(Dense (512, activation='relu', input_shape=(784,))) # input layer\n",
        "model4.add(Dense(512, activation='relu')) # hidden layer1\n",
        "model4.add(Dense(num_classes, activation='softmax'))\n",
        "model4.compile(loss='mean_squared_error', optimizer=RMSprop(lr=0.00001), metrics=['accuracy'])\n",
        "history4 = model4.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=(x_test, y_test))\n",
        "\n",
        "\n",
        "score1 = model1.evaluate(x_test, y_test, verbose=0)\n",
        "score2 = model2.evaluate(x_test, y_test, verbose=0)\n",
        "score3 = model3.evaluate(x_test, y_test, verbose=0)\n",
        "score4 = model4.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print(model1.metrics_names)\n",
        "print('test loss: ', score1[0])\n",
        "print('test acc: ', score1[1])\n",
        "\n",
        "print(model2.metrics_names)\n",
        "print('test loss: ', score2[0])\n",
        "print('test acc: ', score2[1])\n",
        "\n",
        "print(model3.metrics_names)\n",
        "print('test loss: ', score3[0])\n",
        "print('test acc: ', score3[1])\n",
        "\n",
        "print(model4.metrics_names)\n",
        "print('test loss: ', score4[0])\n",
        "print('test acc: ', score4[1])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'acc']\n",
            "test loss:  0.11290730886588217\n",
            "test acc:  0.9805\n",
            "['loss', 'acc']\n",
            "test loss:  2.301802775192261\n",
            "test acc:  0.1135\n",
            "['loss', 'acc']\n",
            "test loss:  1.0921153957953678\n",
            "test acc:  0.7785\n",
            "['loss', 'acc']\n",
            "test loss:  0.010363718561944553\n",
            "test acc:  0.9363\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WAbviFRrv2z",
        "colab_type": "text"
      },
      "source": [
        "## 결론\n",
        "###### 1. lr 0.00001=>0.001 성적좋아짐\n",
        "###### 2,3activation을 하나로 통일해서는 안됨\n",
        "###### 4. loss를 바꾸는것은 경우에 따라 가능함\n",
        "\n",
        "## 참고\n",
        "\n",
        "### activation : 활성화 함수 설정합니다.\n",
        "###### linear’ : 디폴트 값, 입력뉴런과 가중치로 계산된 결과값이 그대로 출력으로 나옵니다.\n",
        "###### relu : rectifier 함수, 은닉층에 주로 쓰입니다.\n",
        "###### sigmoid : 시그모이드 함수, 이진 분류 문제에서 출력층에 주로 쓰입니다.\n",
        "###### softmax : 소프트맥스 함수, 다중 클래스 분류 문제에서 출력층에 주로 쓰입니다.\n",
        "\n",
        "## loss손실 함수, 모델이 최적화에 사용되는 목적 함수입니다. \n",
        "###### categorical_crossentropy \n",
        "###### mse .....\n",
        "\n",
        "## lr 학습률\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1blny40nN71i",
        "colab_type": "text"
      },
      "source": [
        "## sklearn의 classification을 활용한다면??"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZeZqbvlsejD",
        "colab_type": "code",
        "outputId": "eb71bb6b-39e7-46cf-df72-b5df5ab200d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tree = DecisionTreeClassifier()\n",
        "tree.fit(x_train, y_train)\n",
        "pred = tree.predict(x_test)\n",
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_test, pred)\n",
        "print(report)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93       980\n",
            "           1       0.96      0.96      0.96      1135\n",
            "           2       0.87      0.86      0.86      1032\n",
            "           3       0.83      0.86      0.84      1010\n",
            "           4       0.87      0.88      0.88       982\n",
            "           5       0.83      0.84      0.83       892\n",
            "           6       0.89      0.89      0.89       958\n",
            "           7       0.91      0.90      0.90      1028\n",
            "           8       0.82      0.80      0.81       974\n",
            "           9       0.86      0.85      0.85      1009\n",
            "\n",
            "   micro avg       0.88      0.88      0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            " samples avg       0.88      0.88      0.88     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-OLgPDO_wtt",
        "colab_type": "code",
        "outputId": "afe2b42b-6575-4c86-80b7-432520be11f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqENPcSlN_7A",
        "colab_type": "text"
      },
      "source": [
        "# 이미지 처리도 비교적 간단한 케이스라면 \n",
        "# 일반 싸이킷런 머신러닝으로 할 수 있다?? "
      ]
    }
  ]
}